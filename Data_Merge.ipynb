{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb011a6c-4fac-42c2-a270-36a0705070a9",
   "metadata": {},
   "source": [
    "# Data Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f787e0a-ad4d-4c69-8f33-99e87c8b8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import cv2\n",
    "\n",
    "df1 = pd.read_csv('autodl-tmp/final_data_224/rp2k/rp2k_final_224.csv')\n",
    "df2 = pd.read_csv('autodl-tmp/final_data_224/Landmark2021/Landmark2021_final_224.csv')\n",
    "df3 = pd.read_csv('autodl-tmp/final_data_224/JD_Products_10K/JD_product10K_final_224.csv')\n",
    "df4 = pd.read_csv('autodl-tmp/final_data_224/Shopee/Shopee_final_224.csv')\n",
    "df5 = pd.read_csv('autodl-tmp/final_data_224/Art_MET/Art_MET_final_224.csv')\n",
    "df6 = pd.read_csv('autodl-tmp/final_data_224/Aliproducts/Aliproducts_final_224.csv')\n",
    "df7 = pd.read_csv('autodl-tmp/final_data_224/Fruit/Fruit_final_224.csv')\n",
    "df8 = pd.read_csv('autodl-tmp/final_data_224/Stanford_Cars/Stanford_Cars_final_224.csv')\n",
    "df9 = pd.read_csv('autodl-tmp/final_data_224/DeepFashion_CTS/DeepFashion_CTS_final_224.csv')\n",
    "df10 = pd.read_csv('autodl-tmp/final_data_224/Food2022/Food2022_final_224.csv')\n",
    "df11 = pd.read_csv('autodl-tmp/final_data_224/DeepFashion2/DeepFashion2_final_224.csv')\n",
    "df12 = pd.read_csv('autodl-tmp/final_data_224/Fashion_200K/Fashion_200K_final_224.csv')\n",
    "df13 = pd.read_csv('autodl-tmp/final_data_224/Stanford_Products/Stanford_Products_final_224.csv')\n",
    "df14 = pd.read_csv('autodl-tmp/final_data_224/Food2021/Food2021_final_224.csv')\n",
    "display(df1.head(1))\n",
    "display(df2.head(1))\n",
    "display(df3.head(1))\n",
    "display(df4.head(1))\n",
    "display(df5.head(1))\n",
    "display(df6.head(1))\n",
    "display(df7.head(1))\n",
    "display(df8.head(1))\n",
    "display(df9.head(1))\n",
    "display(df10.head(1))\n",
    "display(df11.head(1))\n",
    "display(df12.head(1))\n",
    "display(df13.head(1))\n",
    "display(df14.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2735b1e-5365-46a5-8b2d-9366b5e32775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_labels = df1['labels'].unique()\n",
    "df2_labels = df2['landmark_id'].unique()\n",
    "df3_labels = df3['class'].unique()\n",
    "df4_labels = df4['label_group'].unique()\n",
    "df5_labels = df5['labels'].unique()\n",
    "df6_labels = df6['labels'].unique()\n",
    "df7_labels = df7['labels'].unique()\n",
    "df8_labels = df8['labels'].unique()\n",
    "df9_labels = df9['labels'].unique()\n",
    "df10_labels = df10['labels'].unique()\n",
    "df11_labels = df11['labels'].unique()\n",
    "df12_labels = df12['labels'].unique()\n",
    "df13_labels = df13['labels'].unique()\n",
    "df14_labels = df14['labels'].unique()\n",
    "df1[['new_image_files', 'new_labels']] = [0,0]\n",
    "df2[['new_image_files', 'new_labels']] = [0,0]\n",
    "df3[['new_image_files', 'new_labels']] = [0,0]\n",
    "df4[['new_image_files', 'new_labels']] = [0,0]\n",
    "df5[['new_image_files', 'new_labels']] = [0,0]\n",
    "df6[['new_image_files', 'new_labels']] = [0,0]\n",
    "df7[['new_image_files', 'new_labels']] = [0,0]\n",
    "df8[['new_image_files', 'new_labels']] = [0,0]\n",
    "df9[['new_image_files', 'new_labels']] = [0,0]\n",
    "df10[['new_image_files', 'new_labels']] = [0,0]\n",
    "df11[['new_image_files', 'new_labels']] = [0,0]\n",
    "df12[['new_image_files', 'new_labels']] = [0,0]\n",
    "df13[['new_image_files', 'new_labels']] = [0,0]\n",
    "df14[['new_image_files', 'new_labels']] = [0,0]\n",
    "print(len(df1_labels))\n",
    "print(len(df2_labels))\n",
    "print(len(df3_labels))\n",
    "print(len(df4_labels))\n",
    "print(len(df5_labels))\n",
    "print(len(df6_labels))\n",
    "print(len(df7_labels))\n",
    "print(len(df8_labels))\n",
    "print(len(df9_labels))\n",
    "print(len(df10_labels))\n",
    "print(len(df11_labels))\n",
    "print(len(df12_labels))\n",
    "print(len(df13_labels))\n",
    "print(len(df14_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf063fe7-6787-4587-b235-6acc64f54fe7",
   "metadata": {},
   "source": [
    "* rp2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93298e4d-0beb-400f-8e4a-eff203e567f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'autodl-tmp/final_data_224/rp2k/images'\n",
    "label_count = 0\n",
    "for i in trange(len(df1)):\n",
    "    new_path = df1.loc[i, 'image_files']\n",
    "    df1.loc[i, 'new_image_files'] = new_path\n",
    "    df1.loc[i, 'new_labels'] = np.argwhere(df1_labels==df1.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df1.loc[0, 'new_image_files'])\n",
    "df1.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe77965-c915-4205-bdfe-f075979a49ef",
   "metadata": {},
   "source": [
    "* Landmark_GLDV2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e8918-1b6b-48e3-9672-d675085969b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'autodl-tmp/final_data_224/Landmark2021/images'\n",
    "label_count = len(df1_labels)\n",
    "for i in trange(len(df2)):\n",
    "    file = df2.loc[i, 'id']\n",
    "    path = f'{PATH}/{file}.jpg'\n",
    "    df2.loc[i, 'new_image_files'] = path\n",
    "    df2.loc[i, 'new_labels'] = np.argwhere(df2_labels==df2.loc[i, 'landmark_id'])[0,0]+label_count\n",
    "img = cv2.imread(df2.loc[0, 'new_image_files'])\n",
    "df2.drop(columns=['id', 'landmark_id'], inplace=True)\n",
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2540864-95a4-4a4c-9047-2ee5fdcba51c",
   "metadata": {},
   "source": [
    "* JD_Products_10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c6fad-05a4-4808-beb6-a63c0f02bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'autodl-tmp/final_data_224/JD_Products_10K/images'\n",
    "label_count = len(df1_labels)+len(df2_labels)\n",
    "for i in trange(len(df3)):\n",
    "    path = os.path.join(PATH, df3.loc[i, 'name'])\n",
    "    df3.loc[i, 'new_image_files'] = path\n",
    "    df3.loc[i, 'new_labels'] = np.argwhere(df3_labels==df3.loc[i, 'class'])[0,0]+label_count\n",
    "img = cv2.imread(df3.loc[0, 'new_image_files'])\n",
    "df3.drop(columns=['name', 'class', 'group'], inplace=True)\n",
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015cd84-a156-4628-bc8f-4de65440d80f",
   "metadata": {},
   "source": [
    "* Shopee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da2482-8416-4357-9c1a-a18fae49c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'autodl-tmp/final_data_224/Shopee/images'\n",
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)\n",
    "for i in trange(len(df4)):\n",
    "    path = os.path.join(PATH, df4.loc[i, 'image'])\n",
    "    df4.loc[i, 'new_image_files'] = path\n",
    "    df4.loc[i, 'new_labels'] = np.argwhere(df4_labels==df4.loc[i, 'label_group'])[0,0]+label_count\n",
    "img = cv2.imread(df4.loc[0, 'new_image_files'])\n",
    "df4.drop(columns=['posting_id', 'image','image_phash', 'title', 'label_group'], inplace=True)\n",
    "df4.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d1947-7154-435d-a32c-25aee43c71ae",
   "metadata": {},
   "source": [
    "* Art_MET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf29d3-84be-460a-b3a4-d6000ccb0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'autodl-tmp/final_data_224/Art_MET/images'\n",
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)\n",
    "for i in trange(len(df5)):\n",
    "    path = os.path.join(PATH, df5.loc[i, 'image_files'].split('/')[-1])\n",
    "    df5.loc[i, 'new_image_files'] = path\n",
    "    df5.loc[i, 'new_labels'] = np.argwhere(df5_labels==df5.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df5.loc[0, 'new_image_files'])\n",
    "df5.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df5.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31870ace-5f78-4090-8460-c451ff2730be",
   "metadata": {},
   "source": [
    "* Ali_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1bffde-7e30-4dc0-957d-42fc9d45810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'autodl-tmp/final_data_224/Aliproducts/images'\n",
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)+len(df5_labels)\n",
    "for i in trange(len(df6)):\n",
    "    path = os.path.join(PATH, df6.loc[i, 'image_files'].split('/')[-1])\n",
    "    df6.loc[i, 'new_image_files'] = path\n",
    "    df6.loc[i, 'new_labels'] = np.argwhere(df6_labels==df6.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df6.loc[0, 'new_image_files'])\n",
    "df6.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df6.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fc29cb-b767-4ecc-bade-04eb8a5b21e6",
   "metadata": {},
   "source": [
    "* Fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e733c54-8ebe-4aca-a8a8-e77ffc17f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)+len(df5_labels)+len(df6_labels)\n",
    "for i in trange(len(df7)):\n",
    "    path = df7.loc[i, 'image_files']\n",
    "    new_path = 'autodl-tmp/final_data_224/Fruit/images/'+path.split('/')[-4]+path.split('/')[-1]\n",
    "    df7.loc[i, 'new_image_files'] = new_path\n",
    "    df7.loc[i, 'new_labels'] = np.argwhere(df7_labels==df7.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df7.loc[0, 'new_image_files'])\n",
    "df7.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df7.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6814b40a-5808-40ea-9be4-6a6dad2c59f3",
   "metadata": {},
   "source": [
    "* Stanford_Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230162e7-c716-46cc-a26f-f998e88d3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)+len(df5_labels)+len(df6_labels)+len(df7_labels)\n",
    "for i in trange(len(df8)):\n",
    "    path = 'autodl-tmp/ori_data/Stanford_Cars/'+df8.loc[i, 'image_files']\n",
    "    new_path = 'autodl-tmp/final_data_224/Stanford_Cars/images/'+path.split('/')[-1]\n",
    "    df8.loc[i, 'new_image_files'] = new_path\n",
    "    df8.loc[i, 'new_labels'] = np.argwhere(df8_labels==df8.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df8.loc[0, 'new_image_files'])\n",
    "df8.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df8.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9686ad-3633-44c4-9c93-5a64c6a514e9",
   "metadata": {},
   "source": [
    "* DeepFashion_CTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec814a-0af4-408b-9ac2-4d4f02b93cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)+len(df5_labels)+len(df6_labels)+len(df7_labels)+len(df8_labels)\n",
    "for i in trange(len(df9)):\n",
    "    new_path = df9.loc[i, 'image_files']\n",
    "    df9.loc[i, 'new_image_files'] = new_path\n",
    "    df9.loc[i, 'new_labels'] = np.argwhere(df9_labels==df9.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df9.loc[0, 'new_image_files'])\n",
    "df9.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df9.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de7a042-77d3-4720-ac8a-0b3c72a2ffed",
   "metadata": {},
   "source": [
    "* Food2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bde03-949a-4836-a5a5-f0477efd614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)+len(df5_labels)+len(df6_labels)+len(df7_labels)+len(df8_labels)+len(df9_labels)\n",
    "for i in trange(len(df10)):\n",
    "    new_path = df10.loc[i, 'image_files']\n",
    "    df10.loc[i, 'new_image_files'] = new_path\n",
    "    df10.loc[i, 'new_labels'] = np.argwhere(df10_labels==df10.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df10.loc[0, 'new_image_files'])\n",
    "df10.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df10.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a85a20a-fe00-4553-82e9-b0dff8b9bd41",
   "metadata": {},
   "source": [
    "* DeepFashion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0176b9e9-cd13-48c2-a367-f41e18893e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)+len(df5_labels)+ \\\n",
    "len(df6_labels)+len(df7_labels)+len(df8_labels)+len(df9_labels)+len(df10_labels)\n",
    "for i in trange(len(df11)):\n",
    "    new_path = df11.loc[i, 'image_files']\n",
    "    df11.loc[i, 'new_image_files'] = new_path\n",
    "    df11.loc[i, 'new_labels'] = np.argwhere(df11_labels==df11.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df11.loc[0, 'new_image_files'])\n",
    "df11.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df11.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a86e7ed-e6f6-4b34-848a-6e71c37a5434",
   "metadata": {},
   "source": [
    "* Fashion200K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6afba1-3223-4eaa-a156-ebedc6916a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)+len(df5_labels)+ \\\n",
    "len(df6_labels)+len(df7_labels)+len(df8_labels)+len(df9_labels)+len(df10_labels)+len(df11_labels)\n",
    "for i in trange(len(df12)):\n",
    "    new_path = df12.loc[i, 'image_files']\n",
    "    df12.loc[i, 'new_image_files'] = new_path\n",
    "    df12.loc[i, 'new_labels'] = np.argwhere(df12_labels==df12.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df12.loc[0, 'new_image_files'])\n",
    "df12.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df12.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7aba1a-8017-47a6-af62-f7863c88ce85",
   "metadata": {},
   "source": [
    "* Standford_Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3ddc6-b9ff-459e-bf45-25e8aeb9643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)+len(df5_labels)+len(df6_labels)+ \\\n",
    "len(df7_labels)+len(df8_labels)+len(df9_labels)+len(df10_labels)+len(df11_labels)+len(df12_labels)\n",
    "for i in trange(len(df13)):\n",
    "    path = df13.loc[i, 'image_files']\n",
    "    new_path = 'autodl-tmp/final_data_224/Stanford_Products/images/'+path.split('/')[-1]\n",
    "    df13.loc[i, 'new_image_files'] = new_path\n",
    "    df13.loc[i, 'new_labels'] = np.argwhere(df13_labels==df13.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df13.loc[0, 'new_image_files'])\n",
    "df13.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df13.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e7a7a-056f-412d-992c-be28864bd7c6",
   "metadata": {},
   "source": [
    "* Food2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac59f848-fc99-425a-a291-0d7d72d8a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = len(df1_labels)+len(df2_labels)+len(df3_labels)+len(df4_labels)+len(df5_labels)+len(df6_labels)+ \\\n",
    "len(df7_labels)+len(df8_labels)+len(df9_labels)+len(df10_labels)+len(df11_labels)+len(df12_labels)+len(df13_labels)\n",
    "for i in trange(len(df14)):\n",
    "    new_path = df14.loc[i, 'image_files']\n",
    "    df14.loc[i, 'new_image_files'] = new_path\n",
    "    df14.loc[i, 'new_labels'] = np.argwhere(df14_labels==df14.loc[i, 'labels'])[0,0]+label_count\n",
    "img = cv2.imread(df14.loc[0, 'new_image_files'])\n",
    "df14.drop(columns=['image_files', 'labels'], inplace=True)\n",
    "df14.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf3957-3d62-4e13-990e-08fc7df94ae6",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb3c1a-69e5-480d-aa59-e0e87ad888b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14], axis=0)\n",
    "df_merge['new_labels'] = df_merge['new_labels'].astype('int64')\n",
    "df_merge = df_merge.reset_index(drop=True)\n",
    "df_merge.to_csv('autodl-tmp/final_data_224.csv', index=False)\n",
    "print(df_merge.shape[0],df_merge['new_labels'].nunique())\n",
    "df_merge.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f40524-1945-4ece-9e60-f7b096605e20",
   "metadata": {},
   "source": [
    "#### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d5837-797e-4566-9be7-2df80704658c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 20726/274330 [00:08<01:20, 3133.10it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv('autodl-tmp/final_data_224.csv')\n",
    "new_groups = []\n",
    "for label, group in tqdm(df.groupby('new_labels')):\n",
    "    group = group.reset_index(drop=True)\n",
    "    if len(group)>100:\n",
    "        group = group.sample(100)\n",
    "    new_groups.append(group)\n",
    "new_df = pd.concat(new_groups, axis=0).reset_index(drop=True)\n",
    "print('num:', df.shape[0], 'classes:', df['new_labels'].nunique())\n",
    "print('----->>>')\n",
    "print('num:', new_df.shape[0], 'classes:', new_df['new_labels'].nunique())\n",
    "new_df.to_csv('autodl-tmp/final_data_224_sample.csv')\n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77551a-1cc2-45d2-a16c-7d82405bfc7f",
   "metadata": {},
   "source": [
    "#### Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023636d3-bd94-4f06-bc3b-146e14b434cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "min_ = 20\n",
    "df = pd.read_csv('autodl-tmp/final_data_224_sample.csv')\n",
    "new_groups = []\n",
    "for label, group in tqdm(df.groupby('new_labels')):\n",
    "    group = group.reset_index(drop=True)\n",
    "    if len(group)<min_:\n",
    "        n = min_//len(group)\n",
    "        for i in range(n):\n",
    "            new_groups.append(group)\n",
    "        if min_%len(group)!=0:\n",
    "            new_groups.append(group.sample(min_%len(group)))\n",
    "    else:\n",
    "        new_groups.append(group)\n",
    "new_df = pd.concat(new_groups, axis=0).reset_index(drop=True)\n",
    "print('num:', df.shape[0], 'classes:', df['new_labels'].nunique())\n",
    "print('----->>>')\n",
    "print('num:', new_df.shape[0], 'classes:', new_df['new_labels'].nunique())\n",
    "new_df.to_csv('autodl-tmp/final_data_224_sample_balance.csv', index=False)\n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40956be7-68fd-484d-bf30-6dfe6f66e53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
